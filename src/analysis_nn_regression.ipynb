{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(f'{os.getcwd()}/..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from src.class_computer import link_prediction_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/precomputed_with_classes_3.csv')\n",
    "del df['class']\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_cols = list(df.columns[3:-len(link_prediction_methods)])\n",
    "out_cols = link_prediction_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from keras import Sequential, Input\n",
    "from keras.layers import Dense\n",
    "\n",
    "in_dim = len(in_cols)\n",
    "out_dim = len(out_cols)\n",
    "\n",
    "def build_nn_model():\n",
    "    model = Sequential([\n",
    "        Dense(in_dim*2, input_dim=in_dim, activation='relu'),\n",
    "        Dense(in_dim*2, activation='relu'),\n",
    "        Dense(out_dim),\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy', 'mae'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /home/aruind/Projects/fri-1920-ina-seminar/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n\nEpoch 1/100\n1477/1477 [==============================] - 1s 862us/step - loss: 0.4625 - accuracy: 0.2722 - mae: 0.6381\nEpoch 2/100\n1477/1477 [==============================] - 0s 213us/step - loss: 0.1146 - accuracy: 0.3033 - mae: 0.2782\nEpoch 3/100\n1477/1477 [==============================] - 0s 169us/step - loss: 0.0191 - accuracy: 0.3182 - mae: 0.1033\nEpoch 4/100\n1477/1477 [==============================] - 0s 195us/step - loss: 0.0121 - accuracy: 0.3243 - mae: 0.0736\nEpoch 5/100\n1477/1477 [==============================] - 0s 296us/step - loss: 0.0107 - accuracy: 0.3053 - mae: 0.0671\nEpoch 6/100\n1477/1477 [==============================] - 0s 309us/step - loss: 0.0096 - accuracy: 0.3013 - mae: 0.0640\nEpoch 7/100\n1477/1477 [==============================] - 0s 225us/step - loss: 0.0088 - accuracy: 0.3081 - mae: 0.0606\nEpoch 8/100\n1477/1477 [==============================] - 0s 279us/step - loss: 0.0082 - accuracy: 0.3101 - mae: 0.0584\nEpoch 9/100\n1477/1477 [==============================] - 0s 212us/step - loss: 0.0076 - accuracy: 0.3155 - mae: 0.0563\nEpoch 10/100\n1477/1477 [==============================] - 0s 323us/step - loss: 0.0072 - accuracy: 0.3230 - mae: 0.0552\nEpoch 11/100\n1477/1477 [==============================] - 0s 219us/step - loss: 0.0068 - accuracy: 0.3615 - mae: 0.0537\nEpoch 12/100\n1477/1477 [==============================] - 0s 328us/step - loss: 0.0064 - accuracy: 0.3764 - mae: 0.0509\nEpoch 13/100\n1477/1477 [==============================] - 0s 221us/step - loss: 0.0062 - accuracy: 0.3724 - mae: 0.0501\nEpoch 14/100\n1477/1477 [==============================] - 0s 243us/step - loss: 0.0061 - accuracy: 0.3893 - mae: 0.0496\nEpoch 15/100\n1477/1477 [==============================] - 0s 302us/step - loss: 0.0059 - accuracy: 0.3839 - mae: 0.0489\nEpoch 16/100\n1477/1477 [==============================] - 0s 230us/step - loss: 0.0057 - accuracy: 0.3866 - mae: 0.0465\nEpoch 17/100\n1477/1477 [==============================] - 0s 250us/step - loss: 0.0056 - accuracy: 0.3920 - mae: 0.0462\nEpoch 18/100\n1477/1477 [==============================] - 1s 344us/step - loss: 0.0056 - accuracy: 0.3981 - mae: 0.0463\nEpoch 19/100\n1477/1477 [==============================] - 1s 354us/step - loss: 0.0056 - accuracy: 0.3866 - mae: 0.0456\nEpoch 20/100\n1477/1477 [==============================] - 0s 277us/step - loss: 0.0055 - accuracy: 0.3798 - mae: 0.0453\nEpoch 21/100\n1477/1477 [==============================] - 0s 251us/step - loss: 0.0054 - accuracy: 0.3900 - mae: 0.0451\nEpoch 22/100\n1477/1477 [==============================] - 0s 253us/step - loss: 0.0054 - accuracy: 0.3879 - mae: 0.0447\nEpoch 23/100\n1477/1477 [==============================] - 0s 324us/step - loss: 0.0054 - accuracy: 0.3913 - mae: 0.0460\nEpoch 24/100\n1477/1477 [==============================] - 0s 258us/step - loss: 0.0053 - accuracy: 0.4035 - mae: 0.0445\nEpoch 25/100\n1477/1477 [==============================] - 0s 248us/step - loss: 0.0053 - accuracy: 0.3873 - mae: 0.0444\nEpoch 26/100\n1477/1477 [==============================] - 0s 275us/step - loss: 0.0052 - accuracy: 0.4022 - mae: 0.0439\nEpoch 27/100\n1477/1477 [==============================] - 0s 265us/step - loss: 0.0052 - accuracy: 0.4028 - mae: 0.0440\nEpoch 28/100\n1477/1477 [==============================] - 0s 236us/step - loss: 0.0053 - accuracy: 0.3988 - mae: 0.0442\nEpoch 29/100\n1477/1477 [==============================] - 0s 258us/step - loss: 0.0052 - accuracy: 0.3961 - mae: 0.0444\nEpoch 30/100\n1477/1477 [==============================] - 1s 373us/step - loss: 0.0051 - accuracy: 0.3988 - mae: 0.0433\nEpoch 31/100\n1477/1477 [==============================] - 0s 278us/step - loss: 0.0051 - accuracy: 0.3981 - mae: 0.0435\nEpoch 32/100\n1477/1477 [==============================] - 1s 396us/step - loss: 0.0051 - accuracy: 0.4028 - mae: 0.0438\nEpoch 33/100\n1477/1477 [==============================] - 1s 356us/step - loss: 0.0051 - accuracy: 0.4035 - mae: 0.0436\nEpoch 34/100\n1477/1477 [==============================] - 0s 199us/step - loss: 0.0052 - accuracy: 0.4022 - mae: 0.0444\nEpoch 35/100\n1477/1477 [==============================] - 0s 275us/step - loss: 0.0051 - accuracy: 0.3981 - mae: 0.0431\nEpoch 36/100\n1477/1477 [==============================] - 1s 397us/step - loss: 0.0051 - accuracy: 0.3961 - mae: 0.0434\nEpoch 37/100\n1477/1477 [==============================] - 1s 417us/step - loss: 0.0051 - accuracy: 0.3974 - mae: 0.0434\nEpoch 38/100\n1477/1477 [==============================] - 0s 200us/step - loss: 0.0051 - accuracy: 0.4076 - mae: 0.0437\nEpoch 39/100\n1477/1477 [==============================] - 0s 333us/step - loss: 0.0051 - accuracy: 0.3852 - mae: 0.0435\nEpoch 40/100\n1477/1477 [==============================] - 0s 300us/step - loss: 0.0050 - accuracy: 0.3846 - mae: 0.0428\nEpoch 41/100\n1477/1477 [==============================] - 0s 331us/step - loss: 0.0050 - accuracy: 0.4015 - mae: 0.0429\nEpoch 42/100\n1477/1477 [==============================] - 0s 209us/step - loss: 0.0050 - accuracy: 0.3879 - mae: 0.0429\nEpoch 43/100\n1477/1477 [==============================] - 0s 177us/step - loss: 0.0050 - accuracy: 0.3968 - mae: 0.0427\nEpoch 44/100\n1477/1477 [==============================] - 0s 222us/step - loss: 0.0049 - accuracy: 0.4103 - mae: 0.0423\nEpoch 45/100\n1477/1477 [==============================] - 0s 204us/step - loss: 0.0050 - accuracy: 0.4103 - mae: 0.0426\nEpoch 46/100\n1477/1477 [==============================] - 0s 182us/step - loss: 0.0050 - accuracy: 0.4116 - mae: 0.0425\nEpoch 47/100\n1477/1477 [==============================] - 0s 160us/step - loss: 0.0049 - accuracy: 0.3927 - mae: 0.0423\nEpoch 48/100\n1477/1477 [==============================] - 1s 358us/step - loss: 0.0049 - accuracy: 0.3981 - mae: 0.0423\nEpoch 49/100\n1477/1477 [==============================] - 0s 231us/step - loss: 0.0049 - accuracy: 0.3866 - mae: 0.0421\nEpoch 50/100\n1477/1477 [==============================] - 0s 203us/step - loss: 0.0050 - accuracy: 0.4042 - mae: 0.0430\nEpoch 51/100\n1477/1477 [==============================] - 0s 250us/step - loss: 0.0050 - accuracy: 0.4076 - mae: 0.0428\nEpoch 52/100\n1477/1477 [==============================] - 1s 339us/step - loss: 0.0049 - accuracy: 0.4022 - mae: 0.0423\nEpoch 53/100\n1477/1477 [==============================] - 0s 274us/step - loss: 0.0049 - accuracy: 0.3995 - mae: 0.0424\nEpoch 54/100\n1477/1477 [==============================] - 0s 238us/step - loss: 0.0049 - accuracy: 0.4225 - mae: 0.0425\nEpoch 55/100\n1477/1477 [==============================] - 0s 250us/step - loss: 0.0049 - accuracy: 0.4110 - mae: 0.0421\nEpoch 56/100\n1477/1477 [==============================] - 0s 201us/step - loss: 0.0049 - accuracy: 0.4042 - mae: 0.0422\nEpoch 57/100\n1477/1477 [==============================] - 1s 378us/step - loss: 0.0049 - accuracy: 0.3961 - mae: 0.0421\nEpoch 58/100\n1477/1477 [==============================] - 1s 349us/step - loss: 0.0049 - accuracy: 0.4062 - mae: 0.0423\nEpoch 59/100\n1477/1477 [==============================] - 0s 258us/step - loss: 0.0049 - accuracy: 0.3995 - mae: 0.0425\nEpoch 60/100\n1477/1477 [==============================] - 1s 384us/step - loss: 0.0049 - accuracy: 0.3879 - mae: 0.0425\nEpoch 61/100\n1477/1477 [==============================] - 0s 325us/step - loss: 0.0049 - accuracy: 0.3812 - mae: 0.0432\nEpoch 62/100\n1477/1477 [==============================] - 1s 362us/step - loss: 0.0048 - accuracy: 0.3927 - mae: 0.0418\nEpoch 63/100\n1477/1477 [==============================] - 1s 399us/step - loss: 0.0048 - accuracy: 0.3839 - mae: 0.0424\nEpoch 64/100\n1477/1477 [==============================] - 1s 360us/step - loss: 0.0048 - accuracy: 0.3981 - mae: 0.0419\nEpoch 65/100\n1477/1477 [==============================] - 1s 343us/step - loss: 0.0048 - accuracy: 0.4056 - mae: 0.0418\nEpoch 66/100\n1477/1477 [==============================] - 0s 269us/step - loss: 0.0048 - accuracy: 0.4137 - mae: 0.0420\nEpoch 67/100\n1477/1477 [==============================] - 0s 274us/step - loss: 0.0048 - accuracy: 0.3907 - mae: 0.0430\nEpoch 68/100\n1477/1477 [==============================] - 0s 290us/step - loss: 0.0048 - accuracy: 0.4056 - mae: 0.0417\nEpoch 69/100\n1477/1477 [==============================] - 0s 290us/step - loss: 0.0048 - accuracy: 0.4062 - mae: 0.0434\nEpoch 70/100\n1477/1477 [==============================] - 0s 335us/step - loss: 0.0048 - accuracy: 0.3947 - mae: 0.0423\nEpoch 71/100\n1477/1477 [==============================] - 0s 306us/step - loss: 0.0049 - accuracy: 0.4049 - mae: 0.0430\nEpoch 72/100\n1477/1477 [==============================] - 0s 297us/step - loss: 0.0048 - accuracy: 0.3866 - mae: 0.0427\nEpoch 73/100\n1477/1477 [==============================] - 0s 263us/step - loss: 0.0047 - accuracy: 0.3974 - mae: 0.0412\nEpoch 74/100\n1477/1477 [==============================] - 0s 224us/step - loss: 0.0047 - accuracy: 0.4028 - mae: 0.0416\nEpoch 75/100\n1477/1477 [==============================] - 0s 284us/step - loss: 0.0047 - accuracy: 0.4069 - mae: 0.0418\nEpoch 76/100\n1477/1477 [==============================] - 0s 307us/step - loss: 0.0047 - accuracy: 0.4001 - mae: 0.0416\nEpoch 77/100\n1477/1477 [==============================] - 0s 221us/step - loss: 0.0047 - accuracy: 0.4001 - mae: 0.0411\nEpoch 78/100\n1477/1477 [==============================] - 0s 235us/step - loss: 0.0047 - accuracy: 0.4049 - mae: 0.0411\nEpoch 79/100\n1477/1477 [==============================] - 0s 185us/step - loss: 0.0047 - accuracy: 0.4056 - mae: 0.0413\nEpoch 80/100\n1477/1477 [==============================] - 0s 288us/step - loss: 0.0047 - accuracy: 0.4130 - mae: 0.0415\nEpoch 81/100\n1477/1477 [==============================] - 0s 258us/step - loss: 0.0047 - accuracy: 0.3947 - mae: 0.0413\nEpoch 82/100\n1477/1477 [==============================] - 1s 343us/step - loss: 0.0046 - accuracy: 0.4062 - mae: 0.0411\nEpoch 83/100\n1472/1477 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.4001 - mae: 0.041477/1477 [==============================] - 0s 257us/step - loss: 0.0047 - accuracy: 0.3988 - mae: 0.0415\nEpoch 84/100\n1477/1477 [==============================] - 0s 257us/step - loss: 0.0048 - accuracy: 0.3785 - mae: 0.0422\nEpoch 85/100\n1477/1477 [==============================] - 0s 198us/step - loss: 0.0047 - accuracy: 0.3771 - mae: 0.0415\nEpoch 86/100\n1477/1477 [==============================] - 0s 216us/step - loss: 0.0046 - accuracy: 0.3913 - mae: 0.0409\nEpoch 87/100\n1477/1477 [==============================] - 0s 294us/step - loss: 0.0048 - accuracy: 0.4001 - mae: 0.0425\nEpoch 88/100\n1477/1477 [==============================] - 0s 220us/step - loss: 0.0047 - accuracy: 0.4035 - mae: 0.0411\nEpoch 89/100\n1477/1477 [==============================] - 0s 206us/step - loss: 0.0047 - accuracy: 0.4144 - mae: 0.0413\nEpoch 90/100\n1477/1477 [==============================] - 0s 330us/step - loss: 0.0047 - accuracy: 0.3886 - mae: 0.0410\nEpoch 91/100\n1477/1477 [==============================] - 0s 298us/step - loss: 0.0046 - accuracy: 0.4042 - mae: 0.0410\nEpoch 92/100\n1477/1477 [==============================] - 0s 222us/step - loss: 0.0046 - accuracy: 0.4022 - mae: 0.0411\nEpoch 93/100\n1477/1477 [==============================] - 0s 331us/step - loss: 0.0046 - accuracy: 0.4083 - mae: 0.0407\nEpoch 94/100\n1477/1477 [==============================] - 0s 231us/step - loss: 0.0047 - accuracy: 0.3866 - mae: 0.0413\nEpoch 95/100\n1477/1477 [==============================] - 0s 252us/step - loss: 0.0046 - accuracy: 0.4069 - mae: 0.0406\nEpoch 96/100\n1477/1477 [==============================] - 0s 288us/step - loss: 0.0047 - accuracy: 0.4076 - mae: 0.0422\nEpoch 97/100\n1477/1477 [==============================] - 0s 335us/step - loss: 0.0046 - accuracy: 0.4022 - mae: 0.0408\nEpoch 98/100\n1477/1477 [==============================] - 0s 260us/step - loss: 0.0046 - accuracy: 0.4313 - mae: 0.0420\nEpoch 99/100\n1477/1477 [==============================] - 0s 276us/step - loss: 0.0046 - accuracy: 0.3934 - mae: 0.0407\nEpoch 100/100\n1477/1477 [==============================] - 0s 291us/step - loss: 0.0045 - accuracy: 0.3940 - mae: 0.0407\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x7f8564731550>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[in_cols], df[out_cols], test_size=0.10, random_state=0)\n",
    "\n",
    "normalizer = Normalizer().fit(X_train)\n",
    "\n",
    "X_train = normalizer.transform(X_train)\n",
    "Y_train = y_train\n",
    "\n",
    "X_test = normalizer.transform(X_test)\n",
    "Y_test = y_test\n",
    "\n",
    "regressor = KerasRegressor(build_fn=build_nn_model, batch_size=32,epochs=100)\n",
    "regressor.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      resource_allocation  jaccard_coefficient  preferential_attachment  \\\n1575             0.839080             0.919540                 0.574713   \n1420             0.858289             0.834225                 0.334225   \n991              0.951945             0.955378                 0.411899   \n1399             0.931677             0.936335                 0.338509   \n1579             0.898585             0.825472                 0.365566   \n596              0.968354             0.965190                 0.477848   \n1124             0.949640             0.944844                 0.405276   \n1564             0.917460             0.930159                 0.377778   \n1333             0.836864             0.879237                 0.411017   \n1512             0.944444             0.942460                 0.404762   \n\n      community  sorensen_neighbours  \n1575   0.666667             0.919540  \n1420   0.713904             0.839572  \n991    0.866133             0.947368  \n1399   0.784161             0.936335  \n1579   0.702830             0.865566  \n596    0.778481             0.977848  \n1124   0.856115             0.952038  \n1564   0.860317             0.933333  \n1333   0.760593             0.868644  \n1512   0.857143             0.958333  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>resource_allocation</th>\n      <th>jaccard_coefficient</th>\n      <th>preferential_attachment</th>\n      <th>community</th>\n      <th>sorensen_neighbours</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1575</th>\n      <td>0.839080</td>\n      <td>0.919540</td>\n      <td>0.574713</td>\n      <td>0.666667</td>\n      <td>0.919540</td>\n    </tr>\n    <tr>\n      <th>1420</th>\n      <td>0.858289</td>\n      <td>0.834225</td>\n      <td>0.334225</td>\n      <td>0.713904</td>\n      <td>0.839572</td>\n    </tr>\n    <tr>\n      <th>991</th>\n      <td>0.951945</td>\n      <td>0.955378</td>\n      <td>0.411899</td>\n      <td>0.866133</td>\n      <td>0.947368</td>\n    </tr>\n    <tr>\n      <th>1399</th>\n      <td>0.931677</td>\n      <td>0.936335</td>\n      <td>0.338509</td>\n      <td>0.784161</td>\n      <td>0.936335</td>\n    </tr>\n    <tr>\n      <th>1579</th>\n      <td>0.898585</td>\n      <td>0.825472</td>\n      <td>0.365566</td>\n      <td>0.702830</td>\n      <td>0.865566</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>0.968354</td>\n      <td>0.965190</td>\n      <td>0.477848</td>\n      <td>0.778481</td>\n      <td>0.977848</td>\n    </tr>\n    <tr>\n      <th>1124</th>\n      <td>0.949640</td>\n      <td>0.944844</td>\n      <td>0.405276</td>\n      <td>0.856115</td>\n      <td>0.952038</td>\n    </tr>\n    <tr>\n      <th>1564</th>\n      <td>0.917460</td>\n      <td>0.930159</td>\n      <td>0.377778</td>\n      <td>0.860317</td>\n      <td>0.933333</td>\n    </tr>\n    <tr>\n      <th>1333</th>\n      <td>0.836864</td>\n      <td>0.879237</td>\n      <td>0.411017</td>\n      <td>0.760593</td>\n      <td>0.868644</td>\n    </tr>\n    <tr>\n      <th>1512</th>\n      <td>0.944444</td>\n      <td>0.942460</td>\n      <td>0.404762</td>\n      <td>0.857143</td>\n      <td>0.958333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "Y_test.iloc[0:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.8278412 , 0.7836548 , 0.5305677 , 0.68581736, 0.7977388 ],\n       [0.8858147 , 0.89688474, 0.4035137 , 0.7989643 , 0.90170395],\n       [0.96472526, 0.9732465 , 0.42007554, 0.8472571 , 0.9804982 ],\n       [0.93265086, 0.93908685, 0.40861204, 0.833697  , 0.94599515],\n       [0.8806856 , 0.89373666, 0.39529896, 0.81020427, 0.8975894 ],\n       [0.9553513 , 0.9676637 , 0.4213266 , 0.8334745 , 0.9784336 ],\n       [0.9499214 , 0.9575388 , 0.415835  , 0.84039   , 0.9653685 ],\n       [0.93137866, 0.9352031 , 0.40659574, 0.8292528 , 0.943127  ],\n       [0.8789358 , 0.8890287 , 0.40248874, 0.79500043, 0.8927172 ],\n       [0.9472748 , 0.9555047 , 0.41355392, 0.83933216, 0.963962  ],\n       [0.6345803 , 0.631066  , 0.3463575 , 0.7473288 , 0.63408494],\n       [0.8572977 , 0.86595494, 0.40050998, 0.7587618 , 0.87301946],\n       [0.90558356, 0.90741175, 0.40355015, 0.79698634, 0.91550416],\n       [0.92041194, 0.929328  , 0.41709372, 0.8084777 , 0.9354548 ],\n       [0.9149135 , 0.9208724 , 0.40419123, 0.81784403, 0.9281042 ],\n       [0.6345803 , 0.631066  , 0.3463575 , 0.7473288 , 0.63408494],\n       [0.95188195, 0.96023214, 0.41711304, 0.84024495, 0.96858627],\n       [0.77997637, 0.79490376, 0.44156578, 0.737699  , 0.7905042 ],\n       [0.87812877, 0.8868056 , 0.40372387, 0.7879113 , 0.89158356],\n       [0.5863677 , 0.5431525 , 0.6923595 , 0.6417405 , 0.53857154]],\n      dtype=float32)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "results = regressor.predict(X_test)\n",
    "results[0:20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['resource_allocation',\n 'sorensen_neighbours',\n 'sorensen_neighbours',\n 'sorensen_neighbours',\n 'sorensen_neighbours',\n 'sorensen_neighbours',\n 'sorensen_neighbours',\n 'sorensen_neighbours',\n 'sorensen_neighbours',\n 'sorensen_neighbours',\n 'community',\n 'sorensen_neighbours',\n 'sorensen_neighbours',\n 'sorensen_neighbours',\n 'sorensen_neighbours',\n 'community',\n 'sorensen_neighbours',\n 'jaccard_coefficient',\n 'sorensen_neighbours',\n 'preferential_attachment']"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "predicted = list(map(lambda x: link_prediction_methods[x], np.argmax(results, axis=1)))\n",
    "predicted[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.8656199424676011, 0.1169933765468119)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "Y_score = Y_test.reset_index(drop=True)\n",
    "\n",
    "aucs = []\n",
    "for i, p in enumerate(predicted):\n",
    "    aucs.append(Y_score.loc[i, p])\n",
    "\n",
    "(statistics.mean(aucs), statistics.stdev(aucs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline\n",
    "- AUC mean: 0.850879\n",
    "- AUC std: 0.152039\n",
    "\n",
    "#### NN Regression\n",
    "- AUC mean: 0.8667750401235926\n",
    "- AUC std: 0.1124510633993589"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.8845873166906277, 0.09438093765562915)"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "best = list(map(lambda x: link_prediction_methods[x], np.argmax(Y_test.values, axis=1)))\n",
    "\n",
    "import statistics\n",
    "\n",
    "Y_score = Y_test.reset_index(drop=True)\n",
    "\n",
    "aucs = []\n",
    "for i, p in enumerate(best):\n",
    "    aucs.append(Y_score.loc[i, p])\n",
    "\n",
    "(statistics.mean(aucs), statistics.stdev(aucs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.4121212121212121"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "len(list(filter(lambda x : x, map(lambda x: best[x[0]] == x[1], enumerate(predicted)))))/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "165"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "len(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitenvvenv614d92e831f4432bbbf04e0d7475f739",
   "display_name": "Python 3.6.9 64-bit ('.env': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}